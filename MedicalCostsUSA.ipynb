{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Machine Learning - Medical Cost Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for stopping by! This is my first project from scratch with no insight or input from course instructors so any feedback would be greatly appreciated to help me continue to expand my knowledge! I would also appreciate any insight on where everyone's go-to sources are to research algorithms and python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The United States spends significantly more money on healthcare than any other country around the world.  Spending is expected to continue to grow with The Centers for Medicare and Medicaid Services (CMS) projecting that by 2028, costs will climb to $6.2 trillion, or about $18,000 per person, and will represent about 20 percent of GDP. With an aging population and actual costs of services expected to increase as well it will be of great value for insurance companies, healthcare companies and patients to have an idea of where their future costs may be.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install pip\r\n",
    "#! conda install ipykernel\r\n",
    "#! pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking to answer the following question through prediction modeling: **What will a patient's future healthcare costs look like?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will be using for this project is an open-source data source from Kaggle regarding insurance costs.\r\n",
    "\r\n",
    "To begin we will:\r\n",
    "\r\n",
    "* Import our dataset\r\n",
    "* Create our dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries for this work\r\n",
    "import numpy as np #for dealing with arrays\r\n",
    "import pandas as pd #for dealing with dataframes\r\n",
    "import matplotlib.pyplot as plt #for visualization with matplotlib\r\n",
    "import matplotlib.ticker as ticker\r\n",
    "from matplotlib.ticker import NullFormatter\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns #for visualization with seaborn\r\n",
    "from scipy import stats #for descriptive statistics such as pearson coef\r\n",
    "import itertools\r\n",
    "\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import learning_curve\r\n",
    "from sklearn.model_selection import validation_curve\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.metrics import r2_score,mean_squared_error\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import ExtraTreesClassifier\r\n",
    "\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "\r\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always good to set a seed for reproducibility\r\n",
    "SEED = 7\r\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data set from csv and put into a dataframe\r\n",
    "df = pd.read_csv('insurance.csv')\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing 1 (AKA Data Wrangling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step:\r\n",
    "\r\n",
    "* Verify if any missing values\r\n",
    "* Verify if any duplicates\r\n",
    "* Verify format of the data and reformat if necessary\r\n",
    "* Normalize the data if necessary\r\n",
    "* Perform binning of the data if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\r\n",
    "from pandas_profiling import ProfileReport\r\n",
    "profile = ProfileReport(df, title=\"Basics of the Data\")\r\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables rejected due to high correlation\r\n",
    "rejected_features= list(profile.get_rejected_variables()) \r\n",
    "x_drop= df.drop(rejected_features,axis=1)\r\n",
    "x_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the duplicates\r\n",
    "dup = df.drop_duplicates(keep=\"first\", inplace = True)\r\n",
    "#verify duplicates were dropped\r\n",
    "duplicates2 = df[df.duplicated()]\r\n",
    "verify_duplicates = len(duplicates2)\r\n",
    "verify_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms there are no missing values and we dropped the duplicate rows, now I will verify the types of data in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify types\r\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure dataframe looks good\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe looks good - we are ready to start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will look at:\r\n",
    "\r\n",
    "* Implementing descriptive statistics\r\n",
    "* Group data as necessary\r\n",
    "* Eliminate outliers if necessary\r\n",
    "* Look at data correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); # ; avoid having the matplotlib verbose informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(df.charges.min(), df.charges.max(), 10)\r\n",
    "g = sns.FacetGrid(df, col=\"sex\", hue=\"region\", palette=\"Set1\", col_wrap=2)\r\n",
    "g.map(plt.hist, 'charges', bins=bins, ec=\"k\")\r\n",
    "\r\n",
    "g.axes[-1].legend()\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the Southeast and Northeast have higher costs in both males and females "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = df['age']  \r\n",
    "a1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at outliers in the numeric columns age, charges, children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"charges\"])\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interquartile range is the difference between the 75th percentile and the 25th percentile.\r\n",
    "q1 = df['charges'].quantile(0.25)\r\n",
    "q3 = df['charges'].quantile(0.75)\r\n",
    "iqr = q3 - q1\r\n",
    "print('iqr value is: ',iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find upper and lower limits\r\n",
    "lower_limit = q1 - 1.5 * iqr\r\n",
    "upper_limit = q3 + 1.5 * iqr\r\n",
    "\r\n",
    "print('lower bounds: ' + str(lower_limit))\r\n",
    "print('upper bounds: ' + str(upper_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find amount of outliers in charges\r\n",
    "cols = ['charges']\r\n",
    "((df[cols] < (q1 - 1.5 * iqr)) |(df[cols] > (q3 + 1.5 * iqr))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"age\"])\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The interquartile range is the difference between the 75th percentile and the 25th percentile.\r\n",
    "q1a = df['age'].quantile(0.25)\r\n",
    "q3a = df['age'].quantile(0.75)\r\n",
    "iqr = q3a - q1a\r\n",
    "\r\n",
    "#find upper and lower limits\r\n",
    "lower_limit = q1a - 1.5 * iqr\r\n",
    "upper_limit = q3a + 1.5 * iqr\r\n",
    "\r\n",
    "#find amount of outliers in charges\r\n",
    "cols = ['age']\r\n",
    "((df[cols] < (q1a - 1.5 * iqr)) |(df[cols] > (q3a + 1.5 * iqr))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"children\"])\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find iqr\r\n",
    "q1b = df['children'].quantile(0.25)\r\n",
    "q3b = df['children'].quantile(0.75)\r\n",
    "iqr = q3b - q1b\r\n",
    "\r\n",
    "#find upper and lower limits\r\n",
    "lower_limit = q1b - 1.5 * iqr\r\n",
    "upper_limit = q3b + 1.5 * iqr\r\n",
    "\r\n",
    "#find amount of outliers in charges\r\n",
    "cols = ['children']\r\n",
    "((df[cols] < (q1b - 1.5 * iqr)) |(df[cols] > (q3b + 1.5 * iqr))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we only have outliers in the charges column - 139 of them, and we will drop those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['charges'] \r\n",
    "\r\n",
    "\r\n",
    "df_new = df[~((df[cols] < (q1 - 1.5 * iqr)) |(df[cols] > (q3 + 1.5 * iqr))).any(axis=1)]\r\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets work on finding correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight correlations between age and charges and bmi and charges but none of the correlations give us anything really definitive, so lets take a look at Pearson Coefficients\r\n",
    "\r\n",
    "p-value is < 0.001: we say there is strong evidence that the correlation is significant. \\\r\n",
    "p-value is < 0.05: there is moderate evidence that the correlation is significant. \\\r\n",
    "p-value is < 0.1: there is weak evidence that the correlation is significant. \\\r\n",
    "p-value is > 0.1: there is no evidence that the correlation is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df_new['age'], df_new['charges'])\r\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df_new['bmi'], df_new['charges'])\r\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df_new['children'], df_new['charges'])\r\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age as potential predictor variable of cost\r\n",
    "sns.regplot(x=\"age\", y=\"charges\", data=df)\r\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Children as potential predictor variable of cost\r\n",
    "sns.regplot(x=\"children\", y=\"charges\", data=df)\r\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI as potential predictor variable of cost\r\n",
    "sns.regplot(x=\"bmi\", y=\"charges\", data=df)\r\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df, columns=[\"bmi\",\"charges\"])\r\n",
    "df1\r\n",
    "sns.histplot(\r\n",
    "    df1, x=\"bmi\", y=\"charges\",\r\n",
    "    bins=30, discrete=(False), log_scale=(False),\r\n",
    "    cbar=True, cbar_kws=dict(shrink=.75),\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"children\", y=\"charges\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data to Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = []\r\n",
    "numerical_list = []\r\n",
    "for i in df.columns.tolist():\r\n",
    "    if df[i].dtype=='object':\r\n",
    "        categorical_list.append(i)\r\n",
    "    else:\r\n",
    "        numerical_list.append(i)\r\n",
    "print('Number of categorical features:', str(len(categorical_list)))\r\n",
    "print('Number of numerical features:', str(len(numerical_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['region', 'sex', 'smoker']:\r\n",
    "    df[col] = df[col].astype('category')\r\n",
    "    \r\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.get_dummies(df)\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.charges\r\n",
    "X=df.drop('charges',axis=1)\r\n",
    "feature_name = X.columns.tolist()\r\n",
    "\r\n",
    "\r\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,stratify=df[['sex_female','sex_male','age']])\r\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will perform:\r\n",
    "\r\n",
    "* Feature Selection\r\n",
    "* Feature Scaling\r\n",
    "* Dimensional Reduction if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets pick some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y):\r\n",
    "    cor_list = []\r\n",
    "    # calculate the correlation with y for each feature\r\n",
    "    for i in X.columns.tolist():\r\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\r\n",
    "        cor_list.append(cor)\r\n",
    "    # replace NaN with 0\r\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\r\n",
    "    # feature name\r\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-100:]].columns.tolist()\r\n",
    "    # feature selection? 0 for not select, 1 for select\r\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\r\n",
    "    return cor_support, cor_feature\r\n",
    "\r\n",
    "cor_support, cor_feature = cor_selector(X, y)\r\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\r\n",
    "plt.figure(figsize=(12,10))\r\n",
    "cor = df.corr()\r\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\r\n",
    "cor_target = abs(cor[\"charges\"])\r\n",
    "#Selecting highly correlated features\r\n",
    "relevant_features = cor_target[cor_target>0.5]\r\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"smoker_no\",\"smoker_yes\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\r\n",
    "\r\n",
    "#Adding constant column of ones, mandatory for sm.OLS model\r\n",
    "X_1 = sm.add_constant(X)\r\n",
    "#Fitting sm.OLS model\r\n",
    "model = sm.OLS(y,X_1).fit()\r\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\r\n",
    "cols = list(X.columns)\r\n",
    "pmax = 1\r\n",
    "while (len(cols)>0):\r\n",
    "    p= []\r\n",
    "    X_1 = X[cols]\r\n",
    "    X_1 = sm.add_constant(X_1)\r\n",
    "    model = sm.OLS(y,X_1).fit()\r\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \r\n",
    "    pmax = max(p)\r\n",
    "    feature_with_p_max = p.idxmax()\r\n",
    "    if(pmax>0.05):\r\n",
    "        cols.remove(feature_with_p_max)\r\n",
    "    else:\r\n",
    "        break\r\n",
    "selected_features_BE = cols\r\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\r\n",
    "\r\n",
    "model = LinearRegression()\r\n",
    "#Initializing RFE model\r\n",
    "rfe = RFE(model, 7)\r\n",
    "#Transforming data using RFE\r\n",
    "X_rfe = rfe.fit_transform(X,y)  \r\n",
    "#Fitting the data to model\r\n",
    "model.fit(X_rfe,y)\r\n",
    "print(rfe.support_)\r\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\r\n",
    "nof_list=np.arange(1,13)            \r\n",
    "high_score=0\r\n",
    "#Variable to store the optimum features\r\n",
    "nof=0           \r\n",
    "score_list =[]\r\n",
    "for n in range(len(nof_list)):\r\n",
    "    model = LinearRegression()\r\n",
    "    rfe = RFE(model,nof_list[n])\r\n",
    "    X_train_rfe = rfe.fit_transform(x_train,y_train)\r\n",
    "    X_test_rfe = rfe.transform(x_test)\r\n",
    "    model.fit(X_train_rfe,y_train)\r\n",
    "    score = model.score(X_test_rfe,y_test)\r\n",
    "    score_list.append(score)\r\n",
    "    if(score>high_score):\r\n",
    "        high_score = score\r\n",
    "        nof = nof_list[n]\r\n",
    "print(\"Optimum number of features: %d\" %nof)\r\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(X.columns)\r\n",
    "model = LinearRegression()\r\n",
    "#Initializing RFE model\r\n",
    "rfe = RFE(model, 10)             \r\n",
    "#Transforming data using RFE\r\n",
    "X_rfe = rfe.fit_transform(X,y)  \r\n",
    "#Fitting the data to model\r\n",
    "model.fit(X_rfe,y)              \r\n",
    "temp = pd.Series(rfe.support_,index = cols)\r\n",
    "selected_features_rfe = temp[temp==True].index\r\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\r\n",
    "\r\n",
    "reg = LassoCV()\r\n",
    "reg.fit(X, y)\r\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\r\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\r\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\r\n",
    "import matplotlib\r\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\r\n",
    "imp_coef.plot(kind = \"barh\")\r\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\r\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.linear_model import Ridge\r\n",
    "\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "pipe = Pipeline([\r\n",
    "        ('scaler', StandardScaler()),\r\n",
    "        ('reduce_dim', PCA()),\r\n",
    "        ('regressor', Ridge())\r\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.fit(x_train, y_train)\r\n",
    "print('Testing score: ', pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe.steps[1][1].explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "n_features_to_test = np.arange(1, 11)\r\n",
    "\r\n",
    "alpha_to_test = 2.0**np.arange(-6, +6)\r\n",
    "params = {'reduce_dim__n_components': n_features_to_test,\\\r\n",
    "              'regressor__alpha': alpha_to_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "gridsearch = GridSearchCV(pipe, params, verbose=1).fit(x_train, y_train)\r\n",
    "print('Final score is: ', gridsearch.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_to_test = [StandardScaler(), RobustScaler(), QuantileTransformer()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'scaler': scalers_to_test,\r\n",
    "        'reduce_dim__n_components': n_features_to_test,\\\r\n",
    "        'regressor__alpha': alpha_to_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\r\n",
    "        {'scaler': scalers_to_test,\r\n",
    "         'reduce_dim': [PCA()],\r\n",
    "         'reduce_dim__n_components': n_features_to_test,\\\r\n",
    "         'regressor__alpha': alpha_to_test},\r\n",
    "\r\n",
    "        {'scaler': scalers_to_test,\r\n",
    "         'reduce_dim': [SelectKBest(f_regression)],\r\n",
    "         'reduce_dim__k': n_features_to_test,\\\r\n",
    "         'regressor__alpha': alpha_to_test}\r\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(pipe, params, verbose=1).fit(x_train, y_train)\r\n",
    "print('Final score is: ', gridsearch.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a look at the following models:\r\n",
    "\r\n",
    "* Simple linear regression \r\n",
    "* Multiple linear regression \r\n",
    "* Polynomial regression\r\n",
    "* Support Vector \r\n",
    "* Decision Tree\r\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(x_train,y_train)\r\n",
    "preds = lr.predict(x_test)\r\n",
    "\r\n",
    "\r\n",
    "print('Score: ', lr.score(x_test, y_test))\r\n",
    "print('MSE: ', mean_squared_error(y_test, preds)) \r\n",
    "print('R2:', r2_score(y_test, preds)) \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['charges'], axis = 1)\r\n",
    "y = df.charges\r\n",
    "\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = 0)\r\n",
    "lr = LinearRegression().fit(x_train,y_train)\r\n",
    "\r\n",
    "y_train_pred = lr.predict(x_train)\r\n",
    "y_test_pred = lr.predict(x_test)\r\n",
    "\r\n",
    "print(lr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad but let's try something more complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['charges','sex_female','sex_male','children'], axis = 1)\r\n",
    "Y = df.charges\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "quad = PolynomialFeatures (degree = 2)\r\n",
    "x_quad = quad.fit_transform(X)\r\n",
    "\r\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_quad,Y, random_state = 1)\r\n",
    "\r\n",
    "plr = LinearRegression().fit(x_train,y_train)\r\n",
    "\r\n",
    "y_train_pred = plr.predict(x_train)\r\n",
    "y_test_pred = plr.predict(x_test)\r\n",
    "\r\n",
    "print(plr.score(x_test,y_test))\r\n",
    "print('MSE train data: %.3f, MSE test data: %.3f' % (\r\n",
    "mean_squared_error(y_train,y_train_pred),\r\n",
    "mean_squared_error(y_test,y_test_pred)))\r\n",
    "print('R2 train data: %.3f, R2 test data: %.3f' % (\r\n",
    "r2_score(y_train,y_train_pred),\r\n",
    "r2_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR \r\n",
    "\r\n",
    "supportvectormodel = SVR(kernel='linear')\r\n",
    "svm = supportvectormodel.fit(x_train,y_train)\r\n",
    "\r\n",
    "y_pred_test = svm. predict (x_test)\r\n",
    "\r\n",
    "print(supportvectormodel.score(x_test, y_test))\r\n",
    "print('MSE:', (mean_squared_error(y_test, y_pred_test)))\r\n",
    "print('R2:', (r2_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \r\n",
    "\r\n",
    "# create a regressor object\r\n",
    "decT = DecisionTreeRegressor(random_state = 0) \r\n",
    "  \r\n",
    "# fit the regressor with X and Y data\r\n",
    "dect_predict = decT.fit(x_train, y_train)\r\n",
    "\r\n",
    "y_dec_test = dect_predict.predict(x_test)\r\n",
    "\r\n",
    "print(dect_predict.score(x_test, y_test))\r\n",
    "print('MSE:', (mean_squared_error(y_test, y_dec_test)))\r\n",
    "print('R2:', (r2_score(y_test, y_dec_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.metrics import r2_score,mean_squared_error\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "forest = RandomForestRegressor(n_estimators = 100,\r\n",
    "                              criterion = 'mse',\r\n",
    "                              random_state = 1,\r\n",
    "                              n_jobs = -1)\r\n",
    "frst = forest.fit(x_train,y_train)\r\n",
    "forest_train_pred = forest.predict(x_train)\r\n",
    "forest_test_pred = forest.predict(x_test)\r\n",
    "\r\n",
    "\r\n",
    "print(plr.score(x_test,y_test))\r\n",
    "print('MSE train data: %.3f, MSE test data: %.3f' % (\r\n",
    "mean_squared_error(y_train,forest_train_pred),\r\n",
    "mean_squared_error(y_test,forest_test_pred)))\r\n",
    "print('R2 train data: %.3f, R2 test data: %.3f' % (\r\n",
    "r2_score(y_train,forest_train_pred),\r\n",
    "r2_score(y_test,forest_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\r\n",
    "\r\n",
    "plt.scatter(forest_train_pred,forest_train_pred - y_train,\r\n",
    "          c = 'black', marker = 'o', s = 35, alpha = 0.5,\r\n",
    "          label = 'Train data')\r\n",
    "plt.scatter(forest_test_pred,forest_test_pred - y_test,\r\n",
    "          c = 'b', marker = 'o', s = 35, alpha = 0.5,\r\n",
    "          label = 'Test data')\r\n",
    "plt.xlabel('Predicted values')\r\n",
    "plt.ylabel('Tailings')\r\n",
    "plt.legend(loc = 'upper left')\r\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'red')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result & Implication of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the models that we ran it was clear that the random forest was by far the most accurate with an R2 on the train data of 0.975 and an overall score of 0.833"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python385jvsc74a57bd052c50550139eb27ccc40da107f0157dbb46e9f87ea28c41e96f206d39a85f3d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "3cffe4545cb87d676d7e2e037c764b0760c134b3f05d4485e6274a8459371ad6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}